#########################################
# Environment example for Erastus
# Copy this file to `.env` and fill in values before running the CLI
#########################################

# Required: your API key for the summarizer backend (DeepSeek or compatible chat API)
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Optional: override the default API URL if you use a custom endpoint
#DEEPSEEK_API_URL=https://api.deepseek.com/v1/chat/completions

# Whisper model to use (can be changed by CLI --model)
# Recommended default: large-v3-turbo (choose a model that is installed/available)
WHISPER_MODEL=large-v3-turbo

# Whether to use CUDA / GPU device. Allowed values: true, false, auto
# - true  -> force GPU
# - false -> force CPU
# - auto  -> attempt to detect GPU availability at runtime (default)
USE_CUDA=true

# Preferred language for transcription (unset => auto-detect)
# Examples: pt, en, es
#LANGUAGE=

# Optional: set these paths to override the defaults in config.py
# Provide absolute or relative paths
#UPLOAD_DIR=temp/uploads
#AUDIO_DIR=temp/audios
#TRANSCRIPT_DIR=temp/transcripts
#OUTPUT_DIR=outputs

# Optional runtime tuning
#BATCH_SIZE=16
